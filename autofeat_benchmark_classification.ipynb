{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import warnings\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.datasets import load_iris, load_wine, load_breast_cancer\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "from autofeat import AutoFeatClassifier\n",
    "\n",
    "%matplotlib inline\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'             45'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "k = 45\n",
    "f\"{k:15}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "datasets = [\"iris\", \"wine\", \"breast_cancer\"]\n",
    "\n",
    "# same interface for loading all datasets\n",
    "def load_classification_dataset(name):\n",
    "    # load one of the datasets as X and y\n",
    "    units = {}\n",
    "    if name == \"iris\":\n",
    "        # sklearn iris housing dataset\n",
    "        X, y = load_iris(return_X_y=True)\n",
    "\n",
    "    elif name == \"wine\":\n",
    "        # sklearn wine dataset\n",
    "        X, y = load_wine(return_X_y=True)\n",
    "\n",
    "    elif name == \"breast_cancer\":\n",
    "        # sklearn breast_cancer dataset\n",
    "        X, y = load_breast_cancer(return_X_y=True)\n",
    "\n",
    "    else:\n",
    "        raise RuntimeError(f\"Unknown dataset {name}\")\n",
    "    return np.array(X, dtype=float), np.array(y, dtype=float), units\n",
    "\n",
    "\n",
    "def test_model(dataset, model, param_grid):\n",
    "    # load data\n",
    "    X, y, _ = load_classification_dataset(dataset)\n",
    "    # split in training and test parts\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=12)\n",
    "    if model.__class__.__name__ == \"SVC\":\n",
    "        sscaler = StandardScaler()\n",
    "        X_train = sscaler.fit_transform(X_train)\n",
    "        X_test = sscaler.transform(X_test)\n",
    "    # train model on train split incl cross-validation for parameter selection\n",
    "    with warnings.catch_warnings():\n",
    "        warnings.simplefilter(\"ignore\")\n",
    "        gsmodel = GridSearchCV(model, param_grid, cv=5)\n",
    "        gsmodel.fit(X_train, y_train)\n",
    "    print(\"best params:\", gsmodel.best_params_)\n",
    "    print(\"best score:\", gsmodel.best_score_)\n",
    "    print(\"Acc. on training data:\", accuracy_score(y_train, gsmodel.predict(X_train)))\n",
    "    print(\"Acc. on test data:\", accuracy_score(y_test, gsmodel.predict(X_test)))\n",
    "    return gsmodel.best_estimator_\n",
    "\n",
    "\n",
    "def test_autofeat(dataset, feateng_steps=2):\n",
    "    # load data\n",
    "    X, y, units = load_classification_dataset(dataset)\n",
    "    # split in training and test parts\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=12)\n",
    "    # run autofeat\n",
    "    afreg = AutoFeatClassifier(verbose=1, feateng_steps=feateng_steps, units=units)\n",
    "    # fit autofeat on less data, otherwise ridge reg model with xval will overfit on new features\n",
    "    X_train_tr = afreg.fit_transform(X_train, y_train)\n",
    "    X_test_tr = afreg.transform(X_test)\n",
    "    print(\"autofeat new features:\", len(afreg.new_feat_cols_))\n",
    "    print(\"autofeat Acc. on training data:\", accuracy_score(y_train, afreg.predict(X_train_tr)))\n",
    "    print(\"autofeat Acc. on test data:\", accuracy_score(y_test, afreg.predict(X_test_tr)))\n",
    "    # train rreg on transformed train split incl cross-validation for parameter selection\n",
    "    print(\"# Logistic Regression\")\n",
    "    rreg = LogisticRegression(class_weight=\"balanced\")\n",
    "    param_grid = {\"C\": np.logspace(-4, 4, 10)}\n",
    "    with warnings.catch_warnings():\n",
    "        warnings.simplefilter(\"ignore\")\n",
    "        gsmodel = GridSearchCV(rreg, param_grid, cv=5)\n",
    "        gsmodel.fit(X_train_tr, y_train)\n",
    "    print(\"best params:\", gsmodel.best_params_)\n",
    "    print(\"best score:\", gsmodel.best_score_)\n",
    "    print(\"Acc. on training data:\", accuracy_score(y_train, gsmodel.predict(X_train_tr)))\n",
    "    print(\"Acc. on test data:\", accuracy_score(y_test, gsmodel.predict(X_test_tr)))\n",
    "    print(\"# Random Forest\")\n",
    "    rforest = RandomForestClassifier(n_estimators=100, random_state=13)\n",
    "    param_grid = {\"min_samples_leaf\": [0.0001, 0.001, 0.01, 0.05, 0.1, 0.2]}\n",
    "    gsmodel = GridSearchCV(rforest, param_grid, cv=5)\n",
    "    gsmodel.fit(X_train_tr, y_train)\n",
    "    print(\"best params:\", gsmodel.best_params_)\n",
    "    print(\"best score:\", gsmodel.best_score_)\n",
    "    print(\"Acc. on training data:\", accuracy_score(y_train, gsmodel.predict(X_train_tr)))\n",
    "    print(\"Acc. on test data:\", accuracy_score(y_test, gsmodel.predict(X_test_tr)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#### iris\n",
      "(150, 4) [0. 1. 2.]\n",
      "#### wine\n",
      "(178, 13) [0. 1. 2.]\n",
      "#### breast_cancer\n",
      "(569, 30) [0. 1.]\n"
     ]
    }
   ],
   "source": [
    "for dsname in datasets:\n",
    "    print(\"####\", dsname)\n",
    "    X, y, _ = load_classification_dataset(dsname)\n",
    "    print(X.shape, np.unique(y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#### iris\n",
      "best params: {'C': 0.3593813663804626}\n",
      "best score: 0.9666666666666666\n",
      "Acc. on training data: 0.9666666666666667\n",
      "Acc. on test data: 0.9666666666666667\n",
      "#### wine\n",
      "best params: {'C': 0.3593813663804626}\n",
      "best score: 0.9364532019704435\n",
      "Acc. on training data: 0.9507042253521126\n",
      "Acc. on test data: 0.9444444444444444\n",
      "#### breast_cancer\n",
      "best params: {'C': 21.54434690031882}\n",
      "best score: 0.9516483516483516\n",
      "Acc. on training data: 0.9494505494505494\n",
      "Acc. on test data: 0.9385964912280702\n"
     ]
    }
   ],
   "source": [
    "for dsname in datasets:\n",
    "    print(\"####\", dsname)\n",
    "    rreg = LogisticRegression(class_weight=\"balanced\")\n",
    "    params = {\"C\": np.logspace(-4, 4, 10)}\n",
    "    rreg = test_model(dsname, rreg, params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#### iris\n",
      "best params: {'C': 10.0}\n",
      "best score: 0.975\n",
      "Acc. on training data: 0.9916666666666667\n",
      "Acc. on test data: 0.9666666666666667\n",
      "#### wine\n",
      "best params: {'C': 10.0}\n",
      "best score: 0.9785714285714286\n",
      "Acc. on training data: 1.0\n",
      "Acc. on test data: 0.9722222222222222\n",
      "#### breast_cancer\n",
      "best params: {'C': 1.0}\n",
      "best score: 0.9758241758241759\n",
      "Acc. on training data: 0.989010989010989\n",
      "Acc. on test data: 0.9649122807017544\n"
     ]
    }
   ],
   "source": [
    "for dsname in datasets:\n",
    "    print(\"####\", dsname)\n",
    "    svc = SVC(gamma=\"scale\", class_weight=\"balanced\")\n",
    "    params = {\"C\": [1.0, 10.0, 25.0, 50.0, 100.0, 250.0]}\n",
    "    svc = test_model(dsname, svc, params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#### iris\n",
      "best params: {'min_samples_leaf': 0.2}\n",
      "best score: 0.9666666666666668\n",
      "Acc. on training data: 0.9666666666666667\n",
      "Acc. on test data: 0.9333333333333333\n",
      "#### wine\n",
      "best params: {'min_samples_leaf': 0.0001}\n",
      "best score: 0.9859605911330049\n",
      "Acc. on training data: 1.0\n",
      "Acc. on test data: 0.9722222222222222\n",
      "#### breast_cancer\n",
      "best params: {'min_samples_leaf': 0.0001}\n",
      "best score: 0.9582417582417582\n",
      "Acc. on training data: 1.0\n",
      "Acc. on test data: 0.9385964912280702\n"
     ]
    }
   ],
   "source": [
    "for dsname in datasets:\n",
    "    print(\"####\", dsname)\n",
    "    rforest = RandomForestClassifier(n_estimators=100, random_state=13)\n",
    "    params = {\"min_samples_leaf\": [0.0001, 0.001, 0.01, 0.05, 0.1, 0.2]}\n",
    "    rforest = test_model(dsname, rforest, params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#### iris\n",
      "[AutoFeat] The 1 step feature engineering process could generate up to 28 features.\n",
      "[AutoFeat] With 120 data points this new feature matrix would use about 0.00 gb of space.\n",
      "[feateng] Step 1: transformation of original features\n",
      "[feateng] Generated 24 transformed features from 4 original features - done.\n",
      "[feateng] Generated altogether 24 new features in 1 steps\n",
      "[feateng] Removing correlated features, as well as additions at the highest level\n",
      "[feateng] Generated a total of 8 additional features\n",
      "[featsel] Scaling data...done.\n",
      "[featsel] Feature selection run 1/5\n",
      "[featsel] Feature selection run 2/5\n",
      "[featsel] Feature selection run 3/5\n",
      "[featsel] Feature selection run 4/5\n",
      "[featsel] Feature selection run 5/5\n",
      "[featsel] 6 features after 5 feature selection runs\n",
      "[featsel] 5 features after correlation filtering\n",
      "[featsel] 5 features after noise filtering\n",
      "[AutoFeat] Computing 3 new features.\n",
      "[AutoFeat]     3/    3 new features ...done.\n",
      "[AutoFeat] Final dataframe with 7 feature columns (3 new).\n",
      "[AutoFeat] Training final classification model.\n",
      "[AutoFeat] Trained model: largest coefficients:\n",
      "[ 7.05573015  1.04538046 -8.10111061]\n",
      "0.257260 * exp(x002)\n",
      "0.225713 * x003**3\n",
      "0.054580 * 1/x003\n",
      "0.036648 * x001\n",
      "0.023436 * x002\n",
      "[AutoFeat] Final score: 0.9750\n",
      "[AutoFeat] Computing 3 new features.\n",
      "[AutoFeat]     3/    3 new features ...done.\n",
      "autofeat new features: 3\n",
      "autofeat Acc. on training data: 0.975\n",
      "autofeat Acc. on test data: 0.9333333333333333\n",
      "# Logistic Regression\n",
      "best params: {'C': 0.046415888336127774}\n",
      "best score: 0.9666666666666668\n",
      "Acc. on training data: 0.975\n",
      "Acc. on test data: 0.9333333333333333\n",
      "# Random Forest\n",
      "best params: {'min_samples_leaf': 0.0001}\n",
      "best score: 0.9416666666666667\n",
      "Acc. on training data: 1.0\n",
      "Acc. on test data: 0.9666666666666667\n",
      "#### wine\n",
      "[AutoFeat] The 1 step feature engineering process could generate up to 91 features.\n",
      "[AutoFeat] With 142 data points this new feature matrix would use about 0.00 gb of space.\n",
      "[feateng] Step 1: transformation of original features\n",
      "[feateng] Generated 73 transformed features from 13 original features - done.\n",
      "[feateng] Generated altogether 73 new features in 1 steps\n",
      "[feateng] Removing correlated features, as well as additions at the highest level\n",
      "[feateng] Generated a total of 17 additional features\n",
      "[featsel] Scaling data...done.\n",
      "[featsel] Feature selection run 1/5\n",
      "[featsel] Feature selection run 2/5\n",
      "[featsel] Feature selection run 3/5\n",
      "[featsel] Feature selection run 4/5\n",
      "[featsel] Feature selection run 5/5\n",
      "[featsel] 11 features after 5 feature selection runs\n",
      "[featsel] 11 features after correlation filtering\n",
      "[featsel] 11 features after noise filtering\n",
      "[AutoFeat] Computing 3 new features.\n",
      "[AutoFeat]     3/    3 new features ...done.\n",
      "[AutoFeat] Final dataframe with 16 feature columns (3 new).\n",
      "[AutoFeat] Training final classification model.\n",
      "[AutoFeat] Trained model: largest coefficients:\n",
      "[-9.08783419  7.52691381  1.56092037]\n",
      "3.477018 * 1/x001\n",
      "3.039221 * x002\n",
      "2.821952 * x011\n",
      "2.343438 * x006\n",
      "2.230293 * x010\n",
      "1.494690 * 1/x006\n",
      "0.845980 * x009\n",
      "0.758314 * 1/x009\n",
      "0.401331 * x003\n",
      "0.332090 * x000\n",
      "0.009629 * x012\n",
      "[AutoFeat] Final score: 1.0000\n",
      "[AutoFeat] Computing 3 new features.\n",
      "[AutoFeat]     3/    3 new features ...done.\n",
      "autofeat new features: 3\n",
      "autofeat Acc. on training data: 1.0\n",
      "autofeat Acc. on test data: 1.0\n",
      "# Logistic Regression\n",
      "best params: {'C': 0.3593813663804626}\n",
      "best score: 0.9295566502463053\n",
      "Acc. on training data: 0.9507042253521126\n",
      "Acc. on test data: 0.9722222222222222\n",
      "# Random Forest\n",
      "best params: {'min_samples_leaf': 0.0001}\n",
      "best score: 0.9859605911330049\n",
      "Acc. on training data: 1.0\n",
      "Acc. on test data: 0.9722222222222222\n",
      "#### breast_cancer\n",
      "[AutoFeat] The 1 step feature engineering process could generate up to 210 features.\n",
      "[AutoFeat] With 455 data points this new feature matrix would use about 0.00 gb of space.\n",
      "[feateng] Step 1: transformation of original features\n",
      "[feateng] Generated 155 transformed features from 30 original features - done.\n",
      "[feateng] Generated altogether 164 new features in 1 steps\n",
      "[feateng] Removing correlated features, as well as additions at the highest level\n",
      "[feateng] Generated a total of 62 additional features\n",
      "[featsel] Scaling data...done.\n",
      "[featsel] Feature selection run 1/5\n",
      "[featsel] Feature selection run 2/5\n",
      "[featsel] Feature selection run 3/5\n",
      "[featsel] Feature selection run 4/5\n",
      "[featsel] Feature selection run 5/5\n",
      "[featsel] 15 features after 5 feature selection runs\n",
      "[featsel] 11 features after correlation filtering\n",
      "[featsel] 11 features after noise filtering\n",
      "[AutoFeat] Computing 4 new features.\n",
      "[AutoFeat]     4/    4 new features ...done.\n",
      "[AutoFeat] Final dataframe with 34 feature columns (4 new).\n",
      "[AutoFeat] Training final classification model.\n",
      "[AutoFeat] Trained model: largest coefficients:\n",
      "[69.79221697]\n",
      "60.199340 * x027\n",
      "54.665299 * x024\n",
      "20.011706 * x028\n",
      "18.613914 * 1/x013\n",
      "12.839639 * x010\n",
      "3.537713 * x027**3\n",
      "2.885224 * x026\n",
      "1.851664 * x020\n",
      "0.462909 * 1/x023\n",
      "0.415696 * x021\n",
      "0.059964 * 1/x018\n",
      "[AutoFeat] Final score: 0.9758\n",
      "[AutoFeat] Computing 4 new features.\n",
      "[AutoFeat]     4/    4 new features ...done.\n",
      "autofeat new features: 4\n",
      "autofeat Acc. on training data: 0.9758241758241758\n",
      "autofeat Acc. on test data: 0.9824561403508771\n",
      "# Logistic Regression\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "\nAll the 50 fits failed.\nIt is very likely that your model is misconfigured.\nYou can try to debug the error by setting error_score='raise'.\n\nBelow are more details about the failures:\n--------------------------------------------------------------------------------\n50 fits failed with the following error:\nTraceback (most recent call last):\n  File \"/Users/franzi/.pyenv/versions/3.10.2/lib/python3.10/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"/Users/franzi/.pyenv/versions/3.10.2/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py\", line 1196, in fit\n    X, y = self._validate_data(\n  File \"/Users/franzi/.pyenv/versions/3.10.2/lib/python3.10/site-packages/sklearn/base.py\", line 548, in _validate_data\n    self._check_feature_names(X, reset=reset)\n  File \"/Users/franzi/.pyenv/versions/3.10.2/lib/python3.10/site-packages/sklearn/base.py\", line 415, in _check_feature_names\n    feature_names_in = _get_feature_names(X)\n  File \"/Users/franzi/.pyenv/versions/3.10.2/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 1903, in _get_feature_names\n    raise TypeError(\nTypeError: Feature names are only supported if all input features have string names, but your input has ['str', 'str_'] as feature name / column name types. If you want feature names to be stored and validated, you must convert them all to strings, by using X.columns = X.columns.astype(str) for example. Otherwise you can remove feature / column names from your input data, or convert them all to a non-string data type.\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Input \u001b[0;32mIn [8]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m dsname \u001b[38;5;129;01min\u001b[39;00m datasets:\n\u001b[1;32m      2\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m####\u001b[39m\u001b[38;5;124m\"\u001b[39m, dsname)\n\u001b[0;32m----> 3\u001b[0m     \u001b[43mtest_autofeat\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdsname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfeateng_steps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "Input \u001b[0;32mIn [3]\u001b[0m, in \u001b[0;36mtest_autofeat\u001b[0;34m(dataset, feateng_steps)\u001b[0m\n\u001b[1;32m     61\u001b[0m     warnings\u001b[38;5;241m.\u001b[39msimplefilter(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mignore\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     62\u001b[0m     gsmodel \u001b[38;5;241m=\u001b[39m GridSearchCV(rreg, param_grid, cv\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m5\u001b[39m)\n\u001b[0;32m---> 63\u001b[0m     \u001b[43mgsmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train_tr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     64\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbest params:\u001b[39m\u001b[38;5;124m\"\u001b[39m, gsmodel\u001b[38;5;241m.\u001b[39mbest_params_)\n\u001b[1;32m     65\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbest score:\u001b[39m\u001b[38;5;124m\"\u001b[39m, gsmodel\u001b[38;5;241m.\u001b[39mbest_score_)\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.2/lib/python3.10/site-packages/sklearn/model_selection/_search.py:874\u001b[0m, in \u001b[0;36mBaseSearchCV.fit\u001b[0;34m(self, X, y, groups, **fit_params)\u001b[0m\n\u001b[1;32m    868\u001b[0m     results \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_format_results(\n\u001b[1;32m    869\u001b[0m         all_candidate_params, n_splits, all_out, all_more_results\n\u001b[1;32m    870\u001b[0m     )\n\u001b[1;32m    872\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m results\n\u001b[0;32m--> 874\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_run_search\u001b[49m\u001b[43m(\u001b[49m\u001b[43mevaluate_candidates\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    876\u001b[0m \u001b[38;5;66;03m# multimetric is determined here because in the case of a callable\u001b[39;00m\n\u001b[1;32m    877\u001b[0m \u001b[38;5;66;03m# self.scoring the return type is only known after calling\u001b[39;00m\n\u001b[1;32m    878\u001b[0m first_test_score \u001b[38;5;241m=\u001b[39m all_out[\u001b[38;5;241m0\u001b[39m][\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtest_scores\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.2/lib/python3.10/site-packages/sklearn/model_selection/_search.py:1388\u001b[0m, in \u001b[0;36mGridSearchCV._run_search\u001b[0;34m(self, evaluate_candidates)\u001b[0m\n\u001b[1;32m   1386\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_run_search\u001b[39m(\u001b[38;5;28mself\u001b[39m, evaluate_candidates):\n\u001b[1;32m   1387\u001b[0m     \u001b[38;5;124;03m\"\"\"Search all candidates in param_grid\"\"\"\u001b[39;00m\n\u001b[0;32m-> 1388\u001b[0m     \u001b[43mevaluate_candidates\u001b[49m\u001b[43m(\u001b[49m\u001b[43mParameterGrid\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mparam_grid\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.2/lib/python3.10/site-packages/sklearn/model_selection/_search.py:851\u001b[0m, in \u001b[0;36mBaseSearchCV.fit.<locals>.evaluate_candidates\u001b[0;34m(candidate_params, cv, more_results)\u001b[0m\n\u001b[1;32m    844\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(out) \u001b[38;5;241m!=\u001b[39m n_candidates \u001b[38;5;241m*\u001b[39m n_splits:\n\u001b[1;32m    845\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    846\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcv.split and cv.get_n_splits returned \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    847\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124minconsistent results. Expected \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    848\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msplits, got \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(n_splits, \u001b[38;5;28mlen\u001b[39m(out) \u001b[38;5;241m/\u001b[39m\u001b[38;5;241m/\u001b[39m n_candidates)\n\u001b[1;32m    849\u001b[0m     )\n\u001b[0;32m--> 851\u001b[0m \u001b[43m_warn_or_raise_about_fit_failures\u001b[49m\u001b[43m(\u001b[49m\u001b[43mout\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43merror_score\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    853\u001b[0m \u001b[38;5;66;03m# For callable self.scoring, the return type is only know after\u001b[39;00m\n\u001b[1;32m    854\u001b[0m \u001b[38;5;66;03m# calling. If the return type is a dictionary, the error scores\u001b[39;00m\n\u001b[1;32m    855\u001b[0m \u001b[38;5;66;03m# can now be inserted with the correct key. The type checking\u001b[39;00m\n\u001b[1;32m    856\u001b[0m \u001b[38;5;66;03m# of out will be done in `_insert_error_scores`.\u001b[39;00m\n\u001b[1;32m    857\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m callable(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mscoring):\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.2/lib/python3.10/site-packages/sklearn/model_selection/_validation.py:367\u001b[0m, in \u001b[0;36m_warn_or_raise_about_fit_failures\u001b[0;34m(results, error_score)\u001b[0m\n\u001b[1;32m    360\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m num_failed_fits \u001b[38;5;241m==\u001b[39m num_fits:\n\u001b[1;32m    361\u001b[0m     all_fits_failed_message \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m    362\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mAll the \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnum_fits\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m fits failed.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    363\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mIt is very likely that your model is misconfigured.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    364\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mYou can try to debug the error by setting error_score=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mraise\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    365\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mBelow are more details about the failures:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00mfit_errors_summary\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    366\u001b[0m     )\n\u001b[0;32m--> 367\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(all_fits_failed_message)\n\u001b[1;32m    369\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    370\u001b[0m     some_fits_failed_message \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m    371\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00mnum_failed_fits\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m fits failed out of a total of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnum_fits\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    372\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThe score on these train-test partitions for these parameters\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    376\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mBelow are more details about the failures:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00mfit_errors_summary\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    377\u001b[0m     )\n",
      "\u001b[0;31mValueError\u001b[0m: \nAll the 50 fits failed.\nIt is very likely that your model is misconfigured.\nYou can try to debug the error by setting error_score='raise'.\n\nBelow are more details about the failures:\n--------------------------------------------------------------------------------\n50 fits failed with the following error:\nTraceback (most recent call last):\n  File \"/Users/franzi/.pyenv/versions/3.10.2/lib/python3.10/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"/Users/franzi/.pyenv/versions/3.10.2/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py\", line 1196, in fit\n    X, y = self._validate_data(\n  File \"/Users/franzi/.pyenv/versions/3.10.2/lib/python3.10/site-packages/sklearn/base.py\", line 548, in _validate_data\n    self._check_feature_names(X, reset=reset)\n  File \"/Users/franzi/.pyenv/versions/3.10.2/lib/python3.10/site-packages/sklearn/base.py\", line 415, in _check_feature_names\n    feature_names_in = _get_feature_names(X)\n  File \"/Users/franzi/.pyenv/versions/3.10.2/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 1903, in _get_feature_names\n    raise TypeError(\nTypeError: Feature names are only supported if all input features have string names, but your input has ['str', 'str_'] as feature name / column name types. If you want feature names to be stored and validated, you must convert them all to strings, by using X.columns = X.columns.astype(str) for example. Otherwise you can remove feature / column names from your input data, or convert them all to a non-string data type.\n"
     ]
    }
   ],
   "source": [
    "for dsname in datasets:\n",
    "    print(\"####\", dsname)\n",
    "    test_autofeat(dsname, feateng_steps=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
